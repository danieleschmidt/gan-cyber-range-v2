"""
Enhanced Defensive Training System for GAN-Cyber-Range-v2

This module provides advanced training capabilities specifically designed to improve
blue team skills in detecting and responding to AI-generated attack campaigns.
"""

import logging
from typing import Dict, List, Any, Optional, Set, Tuple, Union
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import json
import uuid
import asyncio
from pathlib import Path

logger = logging.getLogger(__name__)


class TrainingDifficulty(Enum):
    """Training difficulty levels"""
    BEGINNER = "beginner"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced" 
    EXPERT = "expert"


class TrainingOutcome(Enum):
    """Training session outcomes"""
    SUCCESS = "success"
    PARTIAL_SUCCESS = "partial_success"
    FAILURE = "failure"
    TIMEOUT = "timeout"


@dataclass
class DefensiveSkill:
    """Represents a defensive skill to be trained"""
    skill_id: str
    name: str
    description: str
    category: str  # e.g., "detection", "analysis", "response"
    difficulty_level: TrainingDifficulty
    prerequisites: List[str] = field(default_factory=list)
    learning_objectives: List[str] = field(default_factory=list)
    assessment_criteria: Dict[str, float] = field(default_factory=dict)


@dataclass
class TrainingScenario:
    """Represents a defensive training scenario"""
    scenario_id: str
    name: str
    description: str
    attack_vector: str
    difficulty: TrainingDifficulty
    target_skills: List[str]
    estimated_duration: int  # minutes
    success_criteria: Dict[str, Any]
    learning_resources: List[str] = field(default_factory=list)
    hints: List[str] = field(default_factory=list)


@dataclass
class TrainingSession:
    """Individual training session data"""
    session_id: str
    participant_id: str
    scenario_id: str
    start_time: datetime
    end_time: Optional[datetime] = None
    outcome: Optional[TrainingOutcome] = None
    score: Optional[float] = None
    time_to_detect: Optional[float] = None  # seconds
    time_to_respond: Optional[float] = None  # seconds
    actions_taken: List[Dict] = field(default_factory=list)
    mistakes_made: List[str] = field(default_factory=list)
    lessons_learned: List[str] = field(default_factory=list)


@dataclass
class LearningPath:
    """Structured learning path for skill development"""
    path_id: str
    name: str
    description: str
    target_role: str  # e.g., "SOC Analyst", "Incident Responder"
    prerequisite_skills: List[str]
    skill_sequence: List[str]  # Ordered list of skills to develop
    estimated_completion_time: int  # hours
    assessment_frequency: int  # sessions between assessments


class DefensiveTrainingEnhancer:
    """Enhanced training system for defensive cybersecurity skills"""
    
    def __init__(self, config_path: Optional[Path] = None):
        self.config_path = config_path
        self.skills_catalog: Dict[str, DefensiveSkill] = {}
        self.scenarios_catalog: Dict[str, TrainingScenario] = {}
        self.learning_paths: Dict[str, LearningPath] = {}
        self.active_sessions: Dict[str, TrainingSession] = {}
        self.participant_progress: Dict[str, Dict] = {}
        
        # Initialize with default skills and scenarios
        self._initialize_default_content()
    
    def _initialize_default_content(self):
        """Initialize default training content"""
        
        # Core defensive skills
        detection_skills = [
            DefensiveSkill(
                skill_id="ai_attack_detection",
                name="AI-Generated Attack Detection",
                description="Identify patterns consistent with AI-generated attack campaigns",
                category="detection",
                difficulty_level=TrainingDifficulty.INTERMEDIATE,
                learning_objectives=[
                    "Recognize statistical anomalies in attack patterns",
                    "Identify high-entropy attack sequences",
                    "Detect unusually high technique diversity"
                ],
                assessment_criteria={
                    "detection_accuracy": 0.85,
                    "false_positive_rate": 0.15,
                    "time_to_detection": 300  # seconds
                }
            ),
            DefensiveSkill(
                skill_id="gan_artifact_analysis",
                name="GAN Artifact Analysis",
                description="Analyze artifacts to determine if they were generated by GANs",
                category="analysis",
                difficulty_level=TrainingDifficulty.ADVANCED,
                prerequisites=["ai_attack_detection"],
                learning_objectives=[
                    "Examine statistical properties of attack data",
                    "Identify GAN-specific artifacts in malware",
                    "Perform reverse engineering of AI models"
                ],
                assessment_criteria={
                    "analysis_accuracy": 0.80,
                    "artifact_identification": 0.90,
                    "time_to_analysis": 600
                }
            ),
            DefensiveSkill(
                skill_id="adaptive_response",
                name="Adaptive Incident Response",
                description="Respond effectively to AI-powered attack campaigns",
                category="response",
                difficulty_level=TrainingDifficulty.EXPERT,
                prerequisites=["ai_attack_detection", "gan_artifact_analysis"],
                learning_objectives=[
                    "Develop counter-strategies for adaptive attacks",
                    "Implement dynamic defensive measures",
                    "Coordinate multi-team response efforts"
                ],
                assessment_criteria={
                    "response_effectiveness": 0.85,
                    "containment_success": 0.90,
                    "time_to_containment": 900
                }
            )
        ]
        
        for skill in detection_skills:
            self.skills_catalog[skill.skill_id] = skill
        
        # Training scenarios
        training_scenarios = [
            TrainingScenario(
                scenario_id="gan_malware_campaign",
                name="GAN-Generated Malware Campaign",
                description="Detect and analyze a campaign using AI-generated malware variants",
                attack_vector="malware",
                difficulty=TrainingDifficulty.INTERMEDIATE,
                target_skills=["ai_attack_detection", "gan_artifact_analysis"],
                estimated_duration=45,
                success_criteria={
                    "detect_gan_generated": True,
                    "identify_variants": 3,
                    "extract_iocs": 10,
                    "max_time_minutes": 45
                },
                learning_resources=[
                    "GAN Malware Detection Guide",
                    "Statistical Analysis Tools",
                    "YARA Rule Creation Tutorial"
                ],
                hints=[
                    "Check entropy levels of binary files",
                    "Look for unusual opcode distributions",
                    "Analyze file metadata patterns"
                ]
            ),
            TrainingScenario(
                scenario_id="adaptive_apt_campaign",
                name="Adaptive APT Campaign",
                description="Respond to an AI-powered APT that adapts to defensive measures",
                attack_vector="apt",
                difficulty=TrainingDifficulty.EXPERT,
                target_skills=["adaptive_response", "ai_attack_detection"],
                estimated_duration=90,
                success_criteria={
                    "identify_adaptation": True,
                    "implement_countermeasures": True,
                    "achieve_containment": True,
                    "document_ttp_evolution": True
                },
                learning_resources=[
                    "Adaptive Threat Response Playbook",
                    "AI Behavior Analysis Framework", 
                    "Dynamic Defense Strategies"
                ],
                hints=[
                    "Monitor for tactical shifts in attack patterns",
                    "Deploy deception technology to confuse AI",
                    "Use multi-layered defensive strategies"
                ]
            )
        ]
        
        for scenario in training_scenarios:
            self.scenarios_catalog[scenario.scenario_id] = scenario
        
        # Learning paths
        soc_analyst_path = LearningPath(
            path_id="soc_analyst_ai_defense",
            name="SOC Analyst - AI Defense Specialization",
            description="Comprehensive training for SOC analysts to detect AI-powered threats",
            target_role="SOC Analyst",
            prerequisite_skills=["basic_log_analysis", "network_security"],
            skill_sequence=[
                "ai_attack_detection",
                "gan_artifact_analysis",
                "adaptive_response"
            ],
            estimated_completion_time=40,
            assessment_frequency=3
        )
        
        self.learning_paths[soc_analyst_path.path_id] = soc_analyst_path
    
    def start_training_session(
        self, 
        participant_id: str, 
        scenario_id: str,
        custom_parameters: Optional[Dict] = None
    ) -> str:
        """Start a new training session"""
        
        if scenario_id not in self.scenarios_catalog:
            raise ValueError(f"Unknown scenario: {scenario_id}")
        
        session_id = str(uuid.uuid4())
        scenario = self.scenarios_catalog[scenario_id]
        
        session = TrainingSession(
            session_id=session_id,
            participant_id=participant_id,
            scenario_id=scenario_id,
            start_time=datetime.now()
        )
        
        self.active_sessions[session_id] = session
        
        logger.info(f"Started training session {session_id} for participant {participant_id}")
        logger.info(f"Scenario: {scenario.name} (Difficulty: {scenario.difficulty.value})")
        
        return session_id
    
    def record_training_action(
        self, 
        session_id: str, 
        action_type: str, 
        action_data: Dict,
        timestamp: Optional[datetime] = None
    ):
        """Record a training action taken by the participant"""
        
        if session_id not in self.active_sessions:
            raise ValueError(f"Unknown session: {session_id}")
        
        session = self.active_sessions[session_id]
        
        action = {
            "timestamp": timestamp or datetime.now(),
            "action_type": action_type,
            "data": action_data
        }
        
        session.actions_taken.append(action)
        
        # Auto-evaluate certain actions
        self._evaluate_action(session, action)
    
    def _evaluate_action(self, session: TrainingSession, action: Dict):
        """Evaluate a training action for correctness and learning"""
        
        scenario = self.scenarios_catalog[session.scenario_id]
        action_type = action["action_type"]
        action_data = action["data"]
        
        # Example evaluations based on action type
        if action_type == "detect_attack":
            if self._is_correct_detection(action_data, scenario):
                logger.info(f"Correct detection in session {session.session_id}")
                if session.time_to_detect is None:
                    time_diff = (action["timestamp"] - session.start_time).total_seconds()
                    session.time_to_detect = time_diff
            else:
                mistake = f"Incorrect detection: {action_data.get('description', 'Unknown')}"
                session.mistakes_made.append(mistake)
        
        elif action_type == "analyze_artifact":
            if self._is_correct_analysis(action_data, scenario):
                logger.info(f"Correct artifact analysis in session {session.session_id}")
            else:
                mistake = f"Incorrect analysis: {action_data.get('finding', 'Unknown')}"
                session.mistakes_made.append(mistake)
        
        elif action_type == "implement_response":
            if self._is_effective_response(action_data, scenario):
                logger.info(f"Effective response in session {session.session_id}")
                if session.time_to_respond is None:
                    time_diff = (action["timestamp"] - session.start_time).total_seconds()
                    session.time_to_respond = time_diff
            else:
                mistake = f"Ineffective response: {action_data.get('response_type', 'Unknown')}"
                session.mistakes_made.append(mistake)
    
    def _is_correct_detection(self, action_data: Dict, scenario: TrainingScenario) -> bool:
        """Evaluate if a detection action is correct"""
        # Simplified logic - in reality this would be more sophisticated
        detected_indicators = action_data.get("indicators", [])
        confidence_score = action_data.get("confidence", 0)
        
        # Check if key indicators were detected
        expected_indicators = self._get_expected_indicators(scenario)
        detected_expected = sum(1 for indicator in detected_indicators 
                               if indicator in expected_indicators)
        
        detection_rate = detected_expected / len(expected_indicators)
        return detection_rate >= 0.7 and confidence_score >= 0.8
    
    def _is_correct_analysis(self, action_data: Dict, scenario: TrainingScenario) -> bool:
        """Evaluate if an analysis action is correct"""
        analysis_type = action_data.get("analysis_type")
        findings = action_data.get("findings", [])
        
        if scenario.scenario_id == "gan_malware_campaign":
            # Check if GAN-generated nature was identified
            gan_identified = any("gan" in finding.lower() or "ai-generated" in finding.lower() 
                                for finding in findings)
            return gan_identified
        
        return len(findings) > 0
    
    def _is_effective_response(self, action_data: Dict, scenario: TrainingScenario) -> bool:
        """Evaluate if a response action is effective"""
        response_type = action_data.get("response_type")
        targets = action_data.get("targets", [])
        
        # Basic effectiveness check
        if response_type in ["isolate", "block", "contain"]:
            return len(targets) > 0
        
        return True
    
    def _get_expected_indicators(self, scenario: TrainingScenario) -> List[str]:
        """Get expected indicators for a scenario"""
        # This would be dynamically generated based on the scenario
        if scenario.scenario_id == "gan_malware_campaign":
            return [
                "high_entropy_binary",
                "unusual_opcode_distribution", 
                "synthetic_metadata",
                "statistical_anomalies",
                "gan_artifacts"
            ]
        elif scenario.scenario_id == "adaptive_apt_campaign":
            return [
                "technique_diversity",
                "tactical_adaptation",
                "behavioral_changes",
                "ai_powered_decisions"
            ]
        
        return []
    
    def complete_training_session(self, session_id: str) -> Dict[str, Any]:
        """Complete a training session and generate assessment"""
        
        if session_id not in self.active_sessions:
            raise ValueError(f"Unknown session: {session_id}")
        
        session = self.active_sessions[session_id]
        session.end_time = datetime.now()
        
        # Calculate session metrics
        duration_minutes = (session.end_time - session.start_time).total_seconds() / 60
        scenario = self.scenarios_catalog[session.scenario_id]
        
        # Determine outcome based on success criteria
        session.outcome, session.score = self._assess_session_outcome(session, scenario)
        
        # Generate learning insights
        learning_insights = self._generate_learning_insights(session, scenario)
        session.lessons_learned.extend(learning_insights)
        
        # Update participant progress
        self._update_participant_progress(session.participant_id, session)
        
        # Move from active to completed
        completed_session = self.active_sessions.pop(session_id)
        
        # Generate assessment report
        assessment_report = {
            "session_id": session_id,
            "participant_id": session.participant_id,
            "scenario": scenario.name,
            "outcome": session.outcome.value,
            "score": session.score,
            "duration_minutes": duration_minutes,
            "time_to_detect": session.time_to_detect,
            "time_to_respond": session.time_to_respond,
            "actions_count": len(session.actions_taken),
            "mistakes_count": len(session.mistakes_made),
            "lessons_learned": session.lessons_learned,
            "recommendations": self._generate_recommendations(session, scenario)
        }
        
        logger.info(f"Completed training session {session_id}: {session.outcome.value} (Score: {session.score:.2f})")
        
        return assessment_report
    
    def _assess_session_outcome(
        self, 
        session: TrainingSession, 
        scenario: TrainingScenario
    ) -> Tuple[TrainingOutcome, float]:
        """Assess the outcome and score of a training session"""
        
        success_criteria = scenario.success_criteria
        score = 0.0
        
        # Check each success criterion
        criteria_met = 0
        total_criteria = len(success_criteria)
        
        # Time-based criteria
        duration_minutes = (session.end_time - session.start_time).total_seconds() / 60
        max_time = success_criteria.get("max_time_minutes", scenario.estimated_duration)
        
        if duration_minutes <= max_time:
            criteria_met += 1
            score += 25  # Time bonus
        
        # Detection criteria
        if session.time_to_detect is not None:
            criteria_met += 1
            score += 25
            
            # Time to detect bonus
            if session.time_to_detect <= 300:  # 5 minutes
                score += 10
        
        # Response criteria
        if session.time_to_respond is not None:
            criteria_met += 1
            score += 25
            
            # Quick response bonus
            if session.time_to_respond <= 600:  # 10 minutes
                score += 10
        
        # Action quality (inverse of mistakes)
        mistake_penalty = min(len(session.mistakes_made) * 5, 20)
        score += max(25 - mistake_penalty, 0)
        
        # Determine outcome based on criteria met and score
        success_rate = criteria_met / max(total_criteria, 1)
        
        if success_rate >= 0.8 and score >= 80:
            outcome = TrainingOutcome.SUCCESS
        elif success_rate >= 0.6 and score >= 60:
            outcome = TrainingOutcome.PARTIAL_SUCCESS
        elif duration_minutes > max_time * 1.5:
            outcome = TrainingOutcome.TIMEOUT
        else:
            outcome = TrainingOutcome.FAILURE
        
        return outcome, min(score, 100.0)
    
    def _generate_learning_insights(
        self, 
        session: TrainingSession, 
        scenario: TrainingScenario
    ) -> List[str]:
        """Generate personalized learning insights"""
        
        insights = []
        
        # Time-based insights
        if session.time_to_detect and session.time_to_detect > 600:
            insights.append("Focus on improving initial threat detection speed through pattern recognition training")
        
        if session.time_to_respond and session.time_to_respond > 900:
            insights.append("Practice incident response procedures to reduce response time")
        
        # Mistake-based insights
        if len(session.mistakes_made) > 3:
            insights.append("Review fundamental concepts before attempting advanced scenarios")
        
        # Action-based insights
        detection_actions = [a for a in session.actions_taken if a["action_type"] == "detect_attack"]
        if len(detection_actions) < 2:
            insights.append("Increase proactive threat hunting activities during scenarios")
        
        # Scenario-specific insights
        if scenario.scenario_id == "gan_malware_campaign":
            if "gan" not in " ".join(session.lessons_learned).lower():
                insights.append("Study GAN-specific artifacts and detection techniques")
        
        return insights
    
    def _generate_recommendations(
        self, 
        session: TrainingSession, 
        scenario: TrainingScenario
    ) -> List[str]:
        """Generate personalized training recommendations"""
        
        recommendations = []
        
        # Skill-based recommendations
        target_skills = scenario.target_skills
        for skill_id in target_skills:
            if skill_id in self.skills_catalog:
                skill = self.skills_catalog[skill_id]
                if session.score < 70:
                    recommendations.append(f"Additional training recommended for: {skill.name}")
        
        # Next steps
        if session.outcome == TrainingOutcome.SUCCESS:
            recommendations.append("Ready for more advanced scenarios in this domain")
            # Suggest next scenario
            next_scenario = self._suggest_next_scenario(session.participant_id, scenario)
            if next_scenario:
                recommendations.append(f"Suggested next scenario: {next_scenario}")
        elif session.outcome == TrainingOutcome.PARTIAL_SUCCESS:
            recommendations.append("Repeat scenario with focus on identified weak areas")
        else:
            recommendations.append("Review prerequisite skills before retrying this scenario")
        
        return recommendations
    
    def _suggest_next_scenario(self, participant_id: str, current_scenario: TrainingScenario) -> Optional[str]:
        """Suggest the next appropriate scenario"""
        
        participant_progress = self.participant_progress.get(participant_id, {})
        
        # Find scenarios with similar or slightly higher difficulty
        current_difficulty = current_scenario.difficulty
        difficulty_order = [
            TrainingDifficulty.BEGINNER,
            TrainingDifficulty.INTERMEDIATE, 
            TrainingDifficulty.ADVANCED,
            TrainingDifficulty.EXPERT
        ]
        
        current_index = difficulty_order.index(current_difficulty)
        target_difficulty = difficulty_order[min(current_index + 1, len(difficulty_order) - 1)]
        
        # Find suitable next scenarios
        for scenario_id, scenario in self.scenarios_catalog.items():
            if (scenario.difficulty == target_difficulty and 
                scenario_id != current_scenario.scenario_id and
                scenario_id not in participant_progress.get("completed_scenarios", [])):
                return scenario.name
        
        return None
    
    def _update_participant_progress(self, participant_id: str, session: TrainingSession):
        """Update participant's training progress"""
        
        if participant_id not in self.participant_progress:
            self.participant_progress[participant_id] = {
                "completed_scenarios": [],
                "skill_assessments": {},
                "total_training_time": 0,
                "avg_score": 0.0,
                "sessions_completed": 0
            }
        
        progress = self.participant_progress[participant_id]
        
        # Update completed scenarios
        if session.scenario_id not in progress["completed_scenarios"]:
            progress["completed_scenarios"].append(session.scenario_id)
        
        # Update skill assessments
        scenario = self.scenarios_catalog[session.scenario_id]
        for skill_id in scenario.target_skills:
            if skill_id not in progress["skill_assessments"]:
                progress["skill_assessments"][skill_id] = []
            progress["skill_assessments"][skill_id].append({
                "session_id": session.session_id,
                "score": session.score,
                "timestamp": session.end_time
            })
        
        # Update aggregate metrics
        duration_minutes = (session.end_time - session.start_time).total_seconds() / 60
        progress["total_training_time"] += duration_minutes
        progress["sessions_completed"] += 1
        
        # Update average score
        total_score = progress["avg_score"] * (progress["sessions_completed"] - 1) + session.score
        progress["avg_score"] = total_score / progress["sessions_completed"]
    
    def get_participant_progress(self, participant_id: str) -> Dict[str, Any]:
        """Get comprehensive progress report for a participant"""
        
        if participant_id not in self.participant_progress:
            return {"error": "Participant not found"}
        
        progress = self.participant_progress[participant_id].copy()
        
        # Add derived insights
        progress["skill_mastery"] = self._calculate_skill_mastery(participant_id)
        progress["recommended_learning_path"] = self._recommend_learning_path(participant_id)
        progress["next_milestones"] = self._identify_next_milestones(participant_id)
        
        return progress
    
    def _calculate_skill_mastery(self, participant_id: str) -> Dict[str, float]:
        """Calculate mastery level for each skill"""
        
        progress = self.participant_progress[participant_id]
        skill_mastery = {}
        
        for skill_id, assessments in progress["skill_assessments"].items():
            if assessments:
                # Weight recent scores more heavily
                recent_scores = [a["score"] for a in assessments[-3:]]  # Last 3 sessions
                mastery_score = sum(recent_scores) / len(recent_scores) / 100.0  # 0-1 scale
                skill_mastery[skill_id] = mastery_score
        
        return skill_mastery
    
    def _recommend_learning_path(self, participant_id: str) -> Optional[str]:
        """Recommend an appropriate learning path"""
        
        progress = self.participant_progress[participant_id]
        skill_mastery = self._calculate_skill_mastery(participant_id)
        
        # Find learning path that matches current skill level
        for path_id, learning_path in self.learning_paths.items():
            prerequisite_met = all(
                skill_mastery.get(skill_id, 0) >= 0.6 
                for skill_id in learning_path.prerequisite_skills
            )
            
            if prerequisite_met:
                # Check if already in progress or completed
                path_skills = learning_path.skill_sequence
                completed_skills = sum(1 for skill_id in path_skills 
                                     if skill_mastery.get(skill_id, 0) >= 0.8)
                
                if completed_skills < len(path_skills):  # Not completed
                    return learning_path.name
        
        return None
    
    def _identify_next_milestones(self, participant_id: str) -> List[str]:
        """Identify next training milestones"""
        
        skill_mastery = self._calculate_skill_mastery(participant_id)
        milestones = []
        
        # Skill mastery milestones
        for skill_id, skill in self.skills_catalog.items():
            current_mastery = skill_mastery.get(skill_id, 0)
            
            if 0.4 <= current_mastery < 0.6:
                milestones.append(f"Achieve proficiency in {skill.name}")
            elif 0.6 <= current_mastery < 0.8:
                milestones.append(f"Master {skill.name}")
        
        # Scenario completion milestones
        progress = self.participant_progress[participant_id]
        completed_count = len(progress["completed_scenarios"])
        total_scenarios = len(self.scenarios_catalog)
        
        if completed_count < total_scenarios:
            milestones.append(f"Complete {total_scenarios - completed_count} more scenarios")
        
        return milestones[:5]  # Top 5 milestones
    
    def export_training_data(self, participant_id: Optional[str] = None) -> Dict[str, Any]:
        """Export training data for analysis"""
        
        export_data = {
            "export_timestamp": datetime.now().isoformat(),
            "skills_catalog": {k: v.__dict__ for k, v in self.skills_catalog.items()},
            "scenarios_catalog": {k: v.__dict__ for k, v in self.scenarios_catalog.items()},
            "learning_paths": {k: v.__dict__ for k, v in self.learning_paths.items()}
        }
        
        if participant_id:
            if participant_id in self.participant_progress:
                export_data["participant_progress"] = self.participant_progress[participant_id]
        else:
            export_data["all_participant_progress"] = self.participant_progress
        
        return export_data
    
    async def simulate_adaptive_scenario(
        self, 
        session_id: str, 
        adaptation_rules: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Simulate an adaptive training scenario that responds to participant actions"""
        
        if session_id not in self.active_sessions:
            raise ValueError(f"Unknown session: {session_id}")
        
        session = self.active_sessions[session_id]
        scenario = self.scenarios_catalog[session.scenario_id]
        
        simulation_results = {
            "adaptations_made": [],
            "difficulty_adjustments": [],
            "new_challenges_introduced": [],
            "participant_responses": []
        }
        
        # Simulate adaptive behavior based on participant actions
        for action in session.actions_taken:
            adaptation = await self._simulate_scenario_adaptation(action, adaptation_rules)
            if adaptation:
                simulation_results["adaptations_made"].append(adaptation)
        
        return simulation_results
    
    async def _simulate_scenario_adaptation(
        self, 
        participant_action: Dict, 
        adaptation_rules: Dict
    ) -> Optional[Dict[str, Any]]:
        """Simulate how a scenario adapts to participant actions"""
        
        action_type = participant_action["action_type"]
        action_data = participant_action["data"]
        
        # Example adaptation logic
        if action_type == "detect_attack":
            confidence = action_data.get("confidence", 0)
            if confidence > 0.9:
                # Participant is detecting well, increase difficulty
                return {
                    "adaptation_type": "increase_stealth",
                    "description": "Attack techniques became more stealthy",
                    "impact": "Detection becomes more challenging"
                }
        
        elif action_type == "implement_response":
            response_type = action_data.get("response_type")
            if response_type == "block":
                # Participant is blocking, simulate evasion
                return {
                    "adaptation_type": "tactical_pivot", 
                    "description": "Attack pivoted to alternative vector",
                    "impact": "New attack path opened"
                }
        
        return None


def create_training_enhancer(config_path: Optional[Path] = None) -> DefensiveTrainingEnhancer:
    """Factory function to create a DefensiveTrainingEnhancer instance"""
    return DefensiveTrainingEnhancer(config_path)


# Example usage and testing
if __name__ == "__main__":
    # Initialize training enhancer
    enhancer = create_training_enhancer()
    
    # Start a training session
    session_id = enhancer.start_training_session(
        participant_id="analyst_001",
        scenario_id="gan_malware_campaign"
    )
    
    # Simulate some training actions
    enhancer.record_training_action(
        session_id=session_id,
        action_type="detect_attack",
        action_data={
            "indicators": ["high_entropy_binary", "statistical_anomalies"],
            "confidence": 0.85,
            "description": "Detected potential GAN-generated malware"
        }
    )
    
    enhancer.record_training_action(
        session_id=session_id,
        action_type="analyze_artifact", 
        action_data={
            "analysis_type": "statistical",
            "findings": ["GAN artifacts detected", "Synthetic metadata identified"],
            "confidence": 0.90
        }
    )
    
    enhancer.record_training_action(
        session_id=session_id,
        action_type="implement_response",
        action_data={
            "response_type": "isolate",
            "targets": ["workstation_001", "server_db_01"],
            "description": "Isolated affected systems"
        }
    )
    
    # Complete the session
    assessment = enhancer.complete_training_session(session_id)
    
    # Print results
    print("Training Session Assessment:")
    print(f"Outcome: {assessment['outcome']}")
    print(f"Score: {assessment['score']:.1f}/100")
    print(f"Duration: {assessment['duration_minutes']:.1f} minutes")
    print("\nLessons Learned:")
    for lesson in assessment['lessons_learned']:
        print(f"  - {lesson}")
    print("\nRecommendations:")
    for recommendation in assessment['recommendations']:
        print(f"  - {recommendation}")
    
    # Check participant progress
    progress = enhancer.get_participant_progress("analyst_001")
    print(f"\nParticipant Progress:")
    print(f"Sessions Completed: {progress['sessions_completed']}")
    print(f"Average Score: {progress['avg_score']:.1f}")
    print(f"Total Training Time: {progress['total_training_time']:.1f} minutes")
    
    if progress['recommended_learning_path']:
        print(f"Recommended Learning Path: {progress['recommended_learning_path']}")