"""
GAN-based malware generation for defensive training purposes.

This module implements advanced generative models to create synthetic malware samples
that maintain realistic characteristics while being safe for training environments.
"""

import torch
import torch.nn as nn
import numpy as np
import logging
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
import hashlib
import random
import string

logger = logging.getLogger(__name__)


@dataclass
class MalwareSignature:
    """Represents a malware signature for detection training"""
    signature_id: str
    signature_type: str  # "hash", "yara", "behavioral"
    signature_data: str
    malware_family: str
    severity: float
    evasion_difficulty: float


@dataclass  
class SyntheticMalware:
    """Represents a generated synthetic malware sample"""
    sample_id: str
    malware_type: str
    binary_data: bytes
    metadata: Dict[str, Any]
    signatures: List[MalwareSignature]
    capabilities: List[str]
    family: str
    size_bytes: int


class MalwareGenerator(nn.Module):
    """Advanced GAN generator for malware synthesis"""
    
    def __init__(
        self, 
        noise_dim: int = 128,
        sequence_length: int = 1024,
        hidden_dim: int = 512
    ):
        super().__init__()
        
        self.noise_dim = noise_dim
        self.sequence_length = sequence_length
        self.hidden_dim = hidden_dim
        
        # LSTM-based generator for sequential data
        self.lstm = nn.LSTM(
            input_size=noise_dim,
            hidden_size=hidden_dim,
            num_layers=3,
            batch_first=True,
            dropout=0.3
        )
        
        # Output layers
        self.output_projection = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, 256),  # Byte values
            nn.Softmax(dim=-1)
        )
        
        # Metadata generator
        self.metadata_head = nn.Sequential(
            nn.Linear(hidden_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 64),  # Metadata vector
            nn.Tanh()
        )
        
    def forward(self, noise: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """Generate malware sequence and metadata"""
        
        # Expand noise to sequence length
        noise_seq = noise.unsqueeze(1).repeat(1, self.sequence_length, 1)
        
        # Generate through LSTM
        lstm_out, (hidden, cell) = self.lstm(noise_seq)
        
        # Generate byte sequence
        byte_sequence = self.output_projection(lstm_out)
        
        # Generate metadata from final hidden state
        metadata = self.metadata_head(hidden[-1])
        
        return byte_sequence, metadata


class MalwareDiscriminator(nn.Module):
    """Discriminator network for malware GAN"""
    
    def __init__(self, sequence_length: int = 1024, hidden_dim: int = 256):
        super().__init__()
        
        self.sequence_length = sequence_length
        
        # Convolutional layers for byte pattern detection
        self.conv_layers = nn.Sequential(
            nn.Conv1d(256, 128, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool1d(2),
            
            nn.Conv1d(128, 64, kernel_size=3, padding=1),
            nn.ReLU(), 
            nn.MaxPool1d(2),
            
            nn.Conv1d(64, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool1d(64)
        )
        
        # Classification head
        self.classifier = nn.Sequential(
            nn.Linear(32 * 64, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Classify input as real or synthetic malware"""
        
        # Transpose for conv1d (batch, channels, sequence)
        x = x.transpose(1, 2)
        
        # Extract features
        features = self.conv_layers(x)
        
        # Flatten and classify
        features_flat = features.view(features.size(0), -1)
        output = self.classifier(features_flat)
        
        return output


class MalwareGAN:
    """Complete GAN system for malware generation"""
    
    def __init__(
        self,
        sequence_length: int = 1024,
        noise_dim: int = 128,
        device: str = "auto"
    ):
        self.sequence_length = sequence_length
        self.noise_dim = noise_dim
        
        # Device setup
        if device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)
            
        # Initialize networks
        self.generator = MalwareGenerator(
            noise_dim=noise_dim,
            sequence_length=sequence_length
        ).to(self.device)
        
        self.discriminator = MalwareDiscriminator(
            sequence_length=sequence_length
        ).to(self.device)
        
        # Optimizers
        self.g_optimizer = torch.optim.Adam(
            self.generator.parameters(), 
            lr=0.0001, 
            betas=(0.5, 0.999)
        )
        
        self.d_optimizer = torch.optim.Adam(
            self.discriminator.parameters(),
            lr=0.0002,
            betas=(0.5, 0.999) 
        )
        
        # Training state
        self.training_history = {
            'g_loss': [],
            'd_loss': [],
            'diversity_scores': []
        }
        
        logger.info(f"Initialized MalwareGAN on device: {self.device}")
        
    def train(
        self,
        real_malware_data: torch.Tensor,
        epochs: int = 1000,
        batch_size: int = 32,
        save_interval: int = 100
    ) -> Dict[str, List[float]]:
        """Train the malware GAN"""
        
        logger.info(f"Starting malware GAN training for {epochs} epochs")
        
        # Create data loader
        dataset = torch.utils.data.TensorDataset(real_malware_data)
        dataloader = torch.utils.data.DataLoader(
            dataset, 
            batch_size=batch_size, 
            shuffle=True
        )
        
        for epoch in range(epochs):
            epoch_g_losses = []
            epoch_d_losses = []
            
            for batch_idx, (real_batch,) in enumerate(dataloader):
                real_batch = real_batch.to(self.device)
                
                # Train Discriminator
                d_loss = self._train_discriminator(real_batch)
                epoch_d_losses.append(d_loss)
                
                # Train Generator
                g_loss = self._train_generator(real_batch.size(0))
                epoch_g_losses.append(g_loss)
                
            # Record epoch metrics
            avg_g_loss = np.mean(epoch_g_losses)
            avg_d_loss = np.mean(epoch_d_losses)
            
            self.training_history['g_loss'].append(avg_g_loss)
            self.training_history['d_loss'].append(avg_d_loss)
            
            # Calculate diversity
            if epoch % 50 == 0:
                diversity = self._calculate_diversity()
                self.training_history['diversity_scores'].append(diversity)
                
            # Logging
            if epoch % 100 == 0:
                logger.info(
                    f"Epoch {epoch}/{epochs} - "
                    f"G Loss: {avg_g_loss:.4f}, "
                    f"D Loss: {avg_d_loss:.4f}"
                )
                
        logger.info("Malware GAN training completed")
        return self.training_history
        
    def generate_malware_samples(
        self,
        num_samples: int = 100,
        malware_types: List[str] = None,
        target_families: List[str] = None
    ) -> List[SyntheticMalware]:
        """Generate synthetic malware samples"""
        
        if malware_types is None:
            malware_types = ['trojan', 'ransomware', 'backdoor', 'worm']
            
        if target_families is None:
            target_families = ['apt1', 'lazarus', 'fin7', 'carbanak']
        
        logger.info(f"Generating {num_samples} synthetic malware samples")
        
        self.generator.eval()
        synthetic_samples = []
        
        with torch.no_grad():
            batch_size = 32
            for i in range(0, num_samples, batch_size):
                current_batch_size = min(batch_size, num_samples - i)
                
                # Generate noise
                noise = torch.randn(current_batch_size, self.noise_dim, device=self.device)
                
                # Generate samples
                byte_sequences, metadata_vectors = self.generator(noise)
                
                # Convert to synthetic malware objects
                for j in range(current_batch_size):
                    sample = self._create_synthetic_malware(
                        byte_sequences[j],
                        metadata_vectors[j],
                        malware_types,
                        target_families
                    )
                    synthetic_samples.append(sample)
        
        logger.info(f"Generated {len(synthetic_samples)} synthetic malware samples")
        return synthetic_samples
        
    def _train_discriminator(self, real_batch: torch.Tensor) -> float:
        """Train discriminator for one step"""
        
        self.d_optimizer.zero_grad()
        batch_size = real_batch.size(0)
        
        # Train on real data
        real_output = self.discriminator(real_batch)
        real_labels = torch.ones(batch_size, 1, device=self.device)
        real_loss = nn.BCELoss()(real_output, real_labels)
        
        # Train on fake data
        noise = torch.randn(batch_size, self.noise_dim, device=self.device)
        fake_batch, _ = self.generator(noise)
        fake_output = self.discriminator(fake_batch.detach())
        fake_labels = torch.zeros(batch_size, 1, device=self.device)
        fake_loss = nn.BCELoss()(fake_output, fake_labels)
        
        # Total loss
        d_loss = real_loss + fake_loss
        d_loss.backward()
        self.d_optimizer.step()
        
        return d_loss.item()
        
    def _train_generator(self, batch_size: int) -> float:
        """Train generator for one step"""
        
        self.g_optimizer.zero_grad()
        
        # Generate fake data
        noise = torch.randn(batch_size, self.noise_dim, device=self.device)
        fake_batch, _ = self.generator(noise)
        fake_output = self.discriminator(fake_batch)
        
        # Generator wants discriminator to think fake is real
        real_labels = torch.ones(batch_size, 1, device=self.device)
        g_loss = nn.BCELoss()(fake_output, real_labels)
        
        g_loss.backward()
        self.g_optimizer.step()
        
        return g_loss.item()
        
    def _calculate_diversity(self) -> float:
        """Calculate diversity of generated samples"""
        
        with torch.no_grad():
            # Generate small batch for diversity calculation
            noise = torch.randn(16, self.noise_dim, device=self.device)
            samples, _ = self.generator(noise)
            
            # Calculate pairwise distances
            samples_flat = samples.view(samples.size(0), -1)
            distances = torch.pdist(samples_flat)
            
            # Diversity is mean pairwise distance
            diversity = distances.mean().item()
            
        return diversity
        
    def _create_synthetic_malware(
        self,
        byte_sequence: torch.Tensor,
        metadata_vector: torch.Tensor,
        malware_types: List[str],
        families: List[str]
    ) -> SyntheticMalware:
        """Create SyntheticMalware object from generated data"""
        
        # Convert byte sequence to binary data
        byte_probs = byte_sequence.cpu().numpy()
        binary_data = np.argmax(byte_probs, axis=-1).astype(np.uint8).tobytes()
        
        # Extract metadata
        metadata_np = metadata_vector.cpu().numpy()
        
        # Classify malware type and family
        malware_type = random.choice(malware_types)
        family = random.choice(families)
        
        # Generate sample ID
        sample_id = hashlib.sha256(binary_data).hexdigest()[:16]
        
        # Generate capabilities based on type
        capabilities = self._generate_capabilities(malware_type, metadata_np)
        
        # Generate signatures
        signatures = self._generate_signatures(binary_data, malware_type, family)
        
        # Create metadata dict
        metadata = {
            'generated_timestamp': torch.datetime.now().isoformat(),
            'generator_version': '1.0',
            'training_epoch': len(self.training_history['g_loss']),
            'metadata_vector': metadata_np.tolist(),
            'confidence_score': float(np.mean(np.abs(metadata_np)))
        }
        
        return SyntheticMalware(
            sample_id=sample_id,
            malware_type=malware_type,
            binary_data=binary_data,
            metadata=metadata,
            signatures=signatures,
            capabilities=capabilities,
            family=family,
            size_bytes=len(binary_data)
        )
        
    def _generate_capabilities(self, malware_type: str, metadata_vector: np.ndarray) -> List[str]:
        """Generate malware capabilities based on type and metadata"""
        
        capability_sets = {
            'trojan': ['file_encryption', 'keylogging', 'screen_capture', 'remote_access'],
            'ransomware': ['file_encryption', 'payment_demand', 'network_spread', 'backup_deletion'],
            'backdoor': ['remote_access', 'privilege_escalation', 'persistence', 'command_execution'],
            'worm': ['network_spread', 'self_replication', 'vulnerability_exploitation', 'payload_delivery']
        }
        
        base_capabilities = capability_sets.get(malware_type, ['unknown_behavior'])
        
        # Add additional capabilities based on metadata
        additional_caps = []
        if metadata_vector[0] > 0.5:
            additional_caps.append('anti_analysis')
        if metadata_vector[1] > 0.5:
            additional_caps.append('network_communication')
        if metadata_vector[2] > 0.5:
            additional_caps.append('data_exfiltration')
            
        return base_capabilities + additional_caps
        
    def _generate_signatures(
        self,
        binary_data: bytes,
        malware_type: str,
        family: str
    ) -> List[MalwareSignature]:
        """Generate detection signatures for the malware"""
        
        signatures = []
        
        # Hash signature
        file_hash = hashlib.sha256(binary_data).hexdigest()
        signatures.append(MalwareSignature(
            signature_id=f"hash_{file_hash[:8]}",
            signature_type="hash",
            signature_data=file_hash,
            malware_family=family,
            severity=0.8,
            evasion_difficulty=0.1
        ))
        
        # Behavioral signature
        behaviors = self._extract_behavioral_patterns(binary_data, malware_type)
        for behavior in behaviors:
            signatures.append(MalwareSignature(
                signature_id=f"behavior_{behavior[:8]}",
                signature_type="behavioral",
                signature_data=behavior,
                malware_family=family,
                severity=0.6,
                evasion_difficulty=0.7
            ))
            
        # YARA-like signature
        yara_rule = self._generate_yara_rule(binary_data, malware_type, family)
        signatures.append(MalwareSignature(
            signature_id=f"yara_{family}",
            signature_type="yara",
            signature_data=yara_rule,
            malware_family=family,
            severity=0.7,
            evasion_difficulty=0.5
        ))
        
        return signatures
        
    def _extract_behavioral_patterns(self, binary_data: bytes, malware_type: str) -> List[str]:
        """Extract behavioral patterns for signature generation"""
        
        patterns = []
        
        # Simple pattern matching (in real implementation would be more sophisticated)
        if b'CreateFile' in binary_data:
            patterns.append('file_manipulation')
        if b'RegSetValue' in binary_data:
            patterns.append('registry_modification')
        if b'socket' in binary_data:
            patterns.append('network_activity')
        if b'crypto' in binary_data:
            patterns.append('cryptographic_operations')
            
        # Add type-specific patterns
        type_patterns = {
            'ransomware': ['mass_file_encryption', 'ransom_note_creation'],
            'trojan': ['stealth_installation', 'data_harvesting'],
            'backdoor': ['persistence_mechanism', 'command_channel'],
            'worm': ['propagation_mechanism', 'vulnerability_scanning']
        }
        
        patterns.extend(type_patterns.get(malware_type, []))
        
        return patterns[:5]  # Limit to 5 patterns
        
    def _generate_yara_rule(self, binary_data: bytes, malware_type: str, family: str) -> str:
        """Generate YARA-like detection rule"""
        
        # Extract some hex patterns
        hex_patterns = []
        for i in range(0, min(len(binary_data), 100), 20):
            chunk = binary_data[i:i+8]
            hex_pattern = chunk.hex().upper()
            hex_patterns.append(hex_pattern)
        
        rule = f"""rule {family}_{malware_type}
{{
    meta:
        description = "Synthetic {malware_type} from {family} family"
        author = "GAN-Cyber-Range"
        date = "2024-01-01"
        
    strings:
        $hex1 = {{ {hex_patterns[0][:16] if hex_patterns else "00 00 00 00"} }}
        $hex2 = {{ {hex_patterns[1][:16] if len(hex_patterns) > 1 else "FF FF FF FF"} }}
        
    condition:
        any of them
}}"""
        
        return rule